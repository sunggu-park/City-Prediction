# -*- coding: utf-8 -*-
"""CSC311_final_build.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kT3LHZgwLK-n4PFwHuwdk47w95QJ6B_i

#Model Preparation
"""

# @title Import libraries

# basic python imports are permitted
import sys
import csv
import random

# numpy and pandas are also permitted
# import numpy is called in the final function
import numpy
import pandas
import re

# MACRO for cities
DB = "Dubai"
RJ = "Rio de Janeiro"
NY = "New York City"
PR = "Paris"

# @title Preprocessing data

"""
[0]       Q1
[1]       Q2
[2]       Q3
[3]       Q4
[4-7]     Q5
[8-13]    Q6
[14]      Q7
[15]      Q8
[16]      Q9
[17-1565] Q10
"""

def clean_data(pd_f, avg, q10_lib):
  """ Take a pandas csv dataframe and clean the data, outputs a cleaned np matrix
  with unrecognized value replaced with mean value
  """
  q10_texts = pd_f['Q10']

  import re
  pattern = r"^[a-zA-Z0-9'\".,?!:;()]+$"
  pattern_clean = r"[\'\".,?!:;()]"

  def vectorization_q10(s: str) -> list:
    tokenized = str(s).lower().split()
    tokenized_cleaned = [s for s in tokenized if re.match(pattern, s)]
    tokenized_cleaned_again = [re.sub(pattern_clean, "", w) for w in tokenized_cleaned]
    return [1 if w in tokenized_cleaned_again  else 0 for w in q10_lib]
  q10_matrix = numpy.array([vectorization_q10(q10_texts[i]) for i in range(len(q10_texts))])


  q6_numerical = [[], [], [], [], [], []]
  for i in range(len(pd_f['id'])):
    if len(pd_f['Q6'][i]) != len("Skyscrapers=>6,Sport=>1,Art and Music=>3,Carnival=>3,Cuisine=>3,Economic=>3"):
      for j in range(6): q6_numerical[j].append(-1)
    else:
      for j in [13, 22, 39, 51, 62, 74]: q6_numerical[j//11 - 1].append(int(pd_f['Q6'][i][j]))
  data = pd_f
  data_fets = numpy.stack([
    data['Q1'], data['Q2'], data['Q3'], data['Q4'],
    # Q5 break down into indicator feature
    [int('Partner' in str(x)) for x in data['Q5']],
    [int('Friends' in str(x)) for x in data['Q5']],
    [int('Siblings' in str(x)) for x in data['Q5']],
    [int('Co-worker' in str(x)) for x in data['Q5']],
    q6_numerical[0], q6_numerical[1], q6_numerical[2], q6_numerical[3], q6_numerical[4], q6_numerical[5],
    data['Q7'], data['Q8'], data['Q9']
], axis = 1)

  for i in range(0, 1549): data_fets = numpy.append(data_fets, numpy.array([q10_matrix[:,i]]).T, axis = 1)

  # Cleaning step 1: remove the response with format error
  def valid_data(v):
    # Q1 - Q4
    for i in [0, 1, 2, 3]:
      if v[i] not in [1, 2, 3, 4, 5]:
        v[i] = avg[i]
    # Q5
    try:
      if (v[4] + v[5] + v[6] + v[7]) == 0:
        for i in [4, 5, 6, 7]:
          v[i] = avg[i]
    except:
      for i in [4, 5, 6, 7]:
        v[i] = avg[i]

    # Q6
    for i in [8, 9, 10, 11, 12, 13]:
      if v[i] not in [1, 2, 3, 4, 5, 6]:
        v[i] = -1
    # Q7 - Q9
    for i in [14, 15, 16]:
      try:
        if numpy.isnan(float(v[i])):
          v[i] = avg[i]
        else:
          v[i] = float(v[i])
      except:
        v[i] = avg[i]
  for i in range(len(data_fets)):
    valid_data(data_fets[i])

  final_data = numpy.empty([len(data_fets),0])
  for i in range(8): final_data = numpy.append(final_data, numpy.array([data_fets[:,i]]).T, axis = 1)

  q6_np = numpy.stack([data_fets[:,x] for x in range(8, 14)]).T
  q6_mean = numpy.mean(q6_np, axis = 1)
  q6_mean_offset = 3.5/q6_mean
  q6_normalized = q6_np * q6_mean_offset.reshape(-1, 1)

  for i in range(6): final_data = numpy.append(final_data, numpy.array([q6_normalized[:,i]]).T, axis = 1)

  for i in range(14, 1566): final_data = numpy.append(final_data, numpy.array([data_fets[:,i]]).T, axis = 1)

  return final_data

"""#Models"""

# @title  Decision tree
def decision_tree(vec) -> str:
  """
  Take a single response as a numpy array of size (1567,), and output the prediction
  as string
  """
  features = ['Q1', 'Q2', 'Q3', 'Q4', 'Q5_partner', 'Q5_friends', 'Q5_siblings', 'Q5_coworker', 'Q6_skycrapers', 'Q6_sport', 'Q6_artmusic', 'Q6_carnival', 'Q6_cuisine', 'Q6_economics', 'Q7', 'Q8', 'Q9']
  v = {}
  for i in range(17):
    v[features[i]] = vec[i]
  # v should be {'Q1': 5.0, 'Q2': 3.0, ...}
  if v['Q7'] <= 15.5:
    # 1
    if v['Q6_skycrapers'] <= 3.43:
      # blue
      if v['Q6_cuisine'] <= 4.019:
        if v['Q1'] <= 4.5:
          return PR
        else:
          return NY
      else:
        if v['Q1'] <= 4.5:
          return NY
        else:
          if v['Q6_economics'] < 5.364:
            return NY
          else:
            return RJ
    else:
      # green
      if v['Q6_economics'] <= 4.032:
        if v['Q2'] <= 4.5:
          return NY
        else:
          return RJ
      else:
        if v['Q7'] <= 8.5:
          return RJ
        else:
          if v['Q2'] <= 4.5:
            return DB
          else:
            return RJ
  else:
    # 2
    if v['Q6_skycrapers'] <= 3.299:
      # purple
      if v['Q4'] < 2.5:
        return DB
      else:
        if v['Q6_economics'] <= 3.256 and v['Q8'] > 8.5:
          return RJ
        else:
          return PR
    else:
      # orange
      if v['Q6_economics'] <= 3.878:
        if v['Q6_sport'] <= 5.259:
          return DB
        else:
          return PR
      else:
        return DB

# @title Knn Model
def dist_all(v, X):
    """
    Compute the squared Euclidean distance between an image `v` (vector) and the
    images in the data matrix `X`.

    Parameters:
        `v` - a numpy array (vector) representing an MNIST image, shape (784,)
        `X` - a data matrix representing a set of MNIST image, shape (N, 784)

    Returns: a vector of squared Euclidean distances between `v` and each image in `X`,
             shape (N,)
    """

    diff = X - v
    sqdiff = diff ** 2
    sumval = numpy.sum(sqdiff, axis=1)

    return sumval

def predict_knn(v, X_train, t_train, k=8):
    """
    Returns a prediction using the k-NN

    Parameters:
        `v` - a numpy array (vector)
        `X_train` - a data matrix
        `t_train` - a vector of ground-truth labels, shape (N,)
        `k` - a positive integer 1 < k <= N, describing the number of closest images
              to consider as part of the knn algorithm

    Returns:
        A string representing the target, whi
    """
    dists = dist_all(v, X_train)

    indices = numpy.argsort(dists)

    rs = t_train[numpy.array(indices)]
    x = numpy.array(rs)
    ts = x.reshape(-1)

    frequency_dict = {}

    for string in ts[:k]:
        if string in frequency_dict:
            frequency_dict[string] += 1
        else:
            frequency_dict[string] = 1

    max_frequency = 0
    most_frequent_element = None

    for element, frequency in frequency_dict.items():
        if frequency > max_frequency:
            max_frequency = frequency
            most_frequent_element = element

    prediction = most_frequent_element

    return prediction

# @title Multinomial Logistic Regression
# ------------------------------------------ Helper functions
def softmax(z):
    """
    Compute the softmax of vector z, or row-wise for a matrix z.

    Parameters:
        `z` - a numpy array of shape (4,) or (N, 4)

    Returns: a numpy array with the same shape as `z`, with the softmax
        activation applied to each row of `z`
    """
    # Take the exponent of z
    expZ = numpy.atleast_2d(numpy.exp(z.astype(float)))

    # The sum over all elements in z and convert to a matrix
    extendedSum = [numpy.sum(expZ, axis=1) for i in range(numpy.atleast_2d(z).shape[1])]
    extendedSum = numpy.stack(extendedSum, axis=1)

    return expZ / extendedSum

def LR_predictOneHot(w, X):
    """
    Computes the prediction made by a logistic regression model with weights `w`
    with input data matrix `X`.

    Parameters:
        `w` - a numpy array of shape (D+1)
        `X` - data matrix of shape (N, D+1)

    Returns: Prediction vector `y` of shape (N, 4). This is a one hot vector
             which indiciates which city the example corresponds to
    """
    z = numpy.matmul(X, w)
    smax = softmax(z)

    # Find the indices with the larges logit
    y = numpy.argmax(smax, axis=1)

    result = []
    for i in range(len(y)):
        if y[i] == 0: result.append([1,0,0,0]) # Dubai
        elif y[i] == 1: result.append([0,1,0,0]) # Rio
        elif y[i] == 2: result.append([0,0,1,0]) # New York
        else: result.append([0,0,0,1]) # Paris

    return numpy.stack(result, axis=0)

def LR_predict(X):
  '''
  Given an input vector X, output the prediction using the LR model.
  The output is a string that reflects one of the 4 cities:
      Dubai, Rio de Janeiro, New York City, Paris
  '''
  # Weights given after 1000 iterations
  weights = numpy.array([[
    [-0.34383155469422616, -0.5409998755806328, 0.5263324579346319, 0.35849897234022754],
    [0.15950615543468558, -0.5251018835479264, 0.7668996032447084,-0.40130387513146665],
    [0.4061685955782517, -0.2543586694431776, -0.6469891049672775, 0.49517917883220425],
    [-0.4816778446723145, 0.8532660773455399, -0.07376967516063666, -0.29781855751258784],
    [-0.13918438474169323, -0.07614875212005219, -0.17573065111023237, 0.3910637879719767],
    [0.27247411773715413, 0.09253486406112132, 0.17967905160904232, -0.5446880334073185],
    [-0.2104945751826607, 0.060687273172202356, 0.40461370454317264, -0.2548064025327149],
    [-0.30659583929986445, -0.15200898148941686, 0.7597255505498839, -0.3011207297606025],
    [0.44726559965432505, -0.39296694788422487, 0.16915130262940115, -0.22344995439950352],
    [0.010938282702750164, 0.3007157955964715, -0.3113264955561139, -0.00032758274310834903],
    [-0.3702319779521466, 0.01488493614846928, -0.10472926169817627, 0.4600763035018529],
    [-0.09647410798732925, 0.4450506192378965, -0.23423243984325295, -0.1143440714073151],
    [-0.11070475560672022, -0.16339400117809952, -0.22920965899621956, 0.5033084157810396],
    [0.09467671479245009, -0.13340932971982078, 0.30640449298742445, -0.2676718780600544],
    [0.14239600237650715, 0.12042405712233752, -0.17119776539771764, -0.09162229410112353],
    [0.03421358990563432, -0.08905394345187687, 0.03258963485308329, 0.02225071869315995],
    [0.017444714533841322, -0.012755066681495975, -0.034179112790505825, 0.029489464938163873],
          ]])
  cities = {0:'Dubai',
            1:'Rio de Janeiro',
            2:'New York City',
            3:'Paris'}

  prediction = LR_predictOneHot(weights, X)[0].astype(float)
  city = numpy.argmax(prediction)

  return cities[city]

# @title Sub-Multinomial Logistics Regression
def MLR_pred(x):
  """
  Compute the prediction made by a multinomial logistic regression model with
  coefficient 'w' and intercept 'b' on the data set with input data 'x'.

  x: a single data point of shape (1,17)
  w: a numpy array of shape (4,17)
  b: a numpy array of shape (4,1)
  label: a dictionary of encoded keys and corresponding city names as values

  Returns: prediction of city's name
  """
  label = {0:'Dubai', 1:'New York City', 2:'Rio de Janeiro', 3:'Paris'}

  w = numpy.array(
      [[-3.91412751e-01,  2.20477347e-01,  5.12174722e-01,
        -8.09252214e-01, -1.56955355e-01,  2.25384932e-01,
        -2.22763215e-01, -4.32713825e-02,  9.56446397e-01,
        -7.46578655e-02, -4.77396269e-01, -3.98676255e-02,
        -4.15262884e-02,  2.57705739e-01,  1.39726004e+00,
         3.28208499e-01, -2.37770976e-01],
       [ 6.40531392e-01,  8.99710976e-01, -5.95790336e-01,
        -3.06646841e-01, -1.39206525e-01,  6.51374091e-02,
         2.54135017e-01,  4.85486034e-01,  3.76972955e-01,
        -3.01237208e-01, -6.42017755e-02, -1.60628279e-01,
        -1.50648018e-01,  4.89008429e-01, -1.72602453e+00,
        -2.04293362e-02,  1.09621934e-01],
       [-7.85088038e-01, -7.52876140e-01, -3.79030864e-01,
         1.47601974e+00, -1.11241763e-01,  1.12388891e-01,
        -4.53019752e-03, -4.15106653e-01, -7.10446664e-01,
         5.44470327e-01, -2.35570412e-02,  4.62150153e-01,
        -2.43834062e-01, -4.08869929e-01,  1.33879879e+00,
        -5.36522368e-02, -8.51121342e-04],
       [ 5.35969397e-01, -3.67312183e-01,  4.62646478e-01,
        -3.60120684e-01,  4.07403643e-01, -4.02911232e-01,
        -2.68416039e-02, -2.71079984e-02, -6.22972687e-01,
        -1.68575253e-01,  5.65155085e-01, -2.61654248e-01,
         4.36008369e-01, -3.37844239e-01, -1.01003430e+00,
        -2.54126926e-01,  1.29000163e-01]])
  b = numpy.array([ 0.4192365 , -0.12471694, -1.04665099,  0.75213143])

  prediction = numpy.dot(x, w.T) + b
  sigmoid = 1 / (1 + numpy.exp(-prediction)) # calculate probability of each prediction
  return label[numpy.argmax(sigmoid)] # return city with highest probability

"""#Final Prediction"""

def max_occ(lst):
    counts = {}
    max_count = 0
    max_item = None

    for item in lst:
        if item in counts: counts[item] += 1
        else: counts[item] = 1

        if counts[item] > max_count:
            max_count = counts[item]
            max_item = item

    return max_item

def predict_all(filename: str) -> list:

  np_load_old = numpy.load
  numpy.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)

  with open('data_matrix.npy', 'rb') as f:
    training_data = numpy.load(f)
  avg = numpy.average(training_data, axis = 0)
  with open('q10_lib.npy', 'rb') as f:
    q10_lib = numpy.load(f)
  with open('target.npy', 'rb') as f:
    target = numpy.load(f)

  responses = pandas.read_csv(filename)

  cleaned_responses = clean_data(responses, avg, q10_lib)


  training_q1_9 = training_data[:,:17]
  x_train = training_q1_9.astype('int32')
  X_mean = numpy.mean(x_train, axis=0)
  X_std = numpy.std(x_train, axis=0)
  epsilon = 0.0001
  X_1_9_norm = (training_q1_9 - X_mean) / (X_std + epsilon)

  x_train = training_data.astype('int32')
  X_mean = numpy.mean(x_train, axis=0)
  X_std = numpy.std(x_train, axis=0)
  X_all_norm = (training_data - X_mean) / (X_std + epsilon)

  pred_lst = []
  for i in cleaned_responses:
    predictions = [decision_tree(i),
                   predict_knn(i[:17], X_1_9_norm, target, 7),
                   predict_knn(i, X_all_norm, target, 2),
                   LR_predict(i[:17]),
                   MLR_pred(i[:17])
                   ]
    pred_lst.append(predictions)

  # for i in cleaned_responses:
    # print(i[:25])

  # for i in pred_lst:
    # print(i[0], i[1], i[2], i[3], i[4], '->', max_occ(i))
    # print(i[0], i[1], i[2], '->', max_occ(i))

  return [max_occ(x) for x in pred_lst]
